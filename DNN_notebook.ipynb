{
 "metadata": {
  "name": "",
  "signature": "sha256:ef0acfd5b7f21605b881588a203ae47577630f1f8ae53495d2b31d0bc1fe1fed"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "\"\"\"\n",
      "A deep neural network with or w/o dropout in one notebook.\n",
      "\n",
      "To train the networks you just need to call the run() function\n",
      "You need to run each cell before doing so.\n",
      "To do so, you can go to \"Cell -> Run All\"\n",
      "Feel free to edit individually each cell and rerun modified ones.\n",
      "\n",
      "You can change global parameters here before running\n",
      "\"\"\"\n",
      "\n",
      "# Which experiment to run\n",
      "MNIST = True\n",
      "DIGITS = False\n",
      "FACES = False\n",
      "TWENTYNEWSGROUPS = False\n",
      "\n",
      "BATCH_SIZE = 100  # default batch size\n",
      "L2_LAMBDA = 1.    # default L2 regularization parameter\n",
      "INIT_LR = 0.01    # initial learning rate, try making it larger"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import numpy\n",
      "import theano\n",
      "import sys\n",
      "import math\n",
      "from theano import tensor as T\n",
      "from theano import shared\n",
      "from theano.tensor.shared_randomstreams import RandomStreams\n",
      "from collections import OrderedDict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "#Activation and helper functions\n",
      "\n",
      "def relu_f(vec):\n",
      "    \"\"\" Wrapper to quickly change the rectified linear unit function \"\"\"\n",
      "    return (vec + abs(vec)) / 2.\n",
      "\n",
      "\n",
      "def softplus_f(v):\n",
      "    return T.log(1 + T.exp(v))\n",
      "\n",
      "\n",
      "def dropout(rng, x, p=0.5):\n",
      "    \"\"\" Zero-out random values in x with probability p using rng \"\"\"\n",
      "    if p > 0. and p < 1.:\n",
      "        seed = rng.randint(2 ** 30)\n",
      "        srng = theano.tensor.shared_randomstreams.RandomStreams(seed)\n",
      "        mask = srng.binomial(n=1, p=1.-p, size=x.shape,\n",
      "                dtype=theano.config.floatX)\n",
      "        return x * mask\n",
      "    return x\n",
      "\n",
      "\n",
      "def build_shared_zeros(shape, name):\n",
      "    \"\"\" Builds a theano shared variable filled with a zeros numpy array \"\"\"\n",
      "    return shared(value=numpy.zeros(shape, dtype=theano.config.floatX),\n",
      "            name=name, borrow=True)\n",
      "\n",
      "\n",
      "class Linear(object):\n",
      "    \"\"\" Basic linear transformation layer (W.X + b) \"\"\"\n",
      "    def __init__(self, rng, input, n_in, n_out, W=None, b=None):\n",
      "        if W is None:\n",
      "            W_values = numpy.asarray(rng.uniform(\n",
      "                low=-numpy.sqrt(6. / (n_in + n_out)),\n",
      "                high=numpy.sqrt(6. / (n_in + n_out)),\n",
      "                size=(n_in, n_out)), dtype=theano.config.floatX)\n",
      "            W_values *= 4  # This works for sigmoid activated networks!\n",
      "            W = theano.shared(value=W_values, name='W', borrow=True)\n",
      "        if b is None:\n",
      "            b = build_shared_zeros((n_out,), 'b')\n",
      "        self.input = input\n",
      "        self.W = W\n",
      "        self.b = b\n",
      "        self.params = [self.W, self.b]\n",
      "        self.output = T.dot(self.input, self.W) + self.b\n",
      "\n",
      "    def __repr__(self):\n",
      "        return \"Linear\"\n",
      "\n",
      "\n",
      "class SigmoidLayer(Linear):\n",
      "    \"\"\" Sigmoid activation layer (sigmoid(W.X + b)) \"\"\"\n",
      "    def __init__(self, rng, input, n_in, n_out, W=None, b=None):\n",
      "        super(SigmoidLayer, self).__init__(rng, input, n_in, n_out, W, b)\n",
      "        self.pre_activation = self.output\n",
      "        self.output = T.nnet.sigmoid(self.pre_activation)\n",
      "\n",
      "\n",
      "class ReLU(Linear):\n",
      "    \"\"\" Rectified Linear Unit activation layer (max(0, W.X + b)) \"\"\"\n",
      "    def __init__(self, rng, input, n_in, n_out, W=None, b=None):\n",
      "        if b is None:\n",
      "            b = build_shared_zeros((n_out,), 'b')\n",
      "        super(ReLU, self).__init__(rng, input, n_in, n_out, W, b)\n",
      "        self.pre_activation = self.output\n",
      "        self.output = relu_f(self.pre_activation)\n",
      "\n",
      "\n",
      "class SoftPlus(Linear):\n",
      "    def __init__(self, rng, input, n_in, n_out, W=None, b=None):\n",
      "        if b is None:\n",
      "            b_values = numpy.zeros((n_out,), dtype=theano.config.floatX)\n",
      "            b = theano.shared(value=b_values, name='b', borrow=True)\n",
      "        super(SoftPlus, self).__init__(rng, input, n_in, n_out, W, b)\n",
      "        self.pre_activation = self.output\n",
      "        self.output = softplus_f(self.pre_activation)\n",
      "\n",
      "\n",
      "class DatasetMiniBatchIterator(object):\n",
      "    \"\"\" Basic mini-batch iterator \"\"\"\n",
      "    def __init__(self, x, y, batch_size=BATCH_SIZE, randomize=False):\n",
      "        self.x = x\n",
      "        self.y = y\n",
      "        self.batch_size = batch_size\n",
      "        self.randomize = randomize\n",
      "        from sklearn.utils import check_random_state\n",
      "        self.rng = check_random_state(42)\n",
      "\n",
      "    def __iter__(self):\n",
      "        n_samples = self.x.shape[0]\n",
      "        if self.randomize:\n",
      "            for _ in xrange(n_samples / BATCH_SIZE):\n",
      "                if BATCH_SIZE > 1:\n",
      "                    i = int(self.rng.rand(1) * ((n_samples+BATCH_SIZE-1) / BATCH_SIZE))\n",
      "                else:\n",
      "                    i = int(math.floor(self.rng.rand(1) * n_samples))\n",
      "                yield (i, self.x[i*self.batch_size:(i+1)*self.batch_size],\n",
      "                       self.y[i*self.batch_size:(i+1)*self.batch_size])\n",
      "        else:\n",
      "            for i in xrange((n_samples + self.batch_size - 1)\n",
      "                            / self.batch_size):\n",
      "                yield (self.x[i*self.batch_size:(i+1)*self.batch_size],\n",
      "                       self.y[i*self.batch_size:(i+1)*self.batch_size])\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class LogisticRegression:\n",
      "    \"\"\" _Multi-class_ Logistic Regression \"\"\"\n",
      "    def __init__(self, rng, input, n_in, n_out, W=None, b=None):\n",
      "        if W != None:\n",
      "            self.W = W\n",
      "        else:\n",
      "            self.W = build_shared_zeros((n_in, n_out), 'W')\n",
      "        if b != None:\n",
      "            self.b = b\n",
      "        else:\n",
      "            self.b = build_shared_zeros((n_out,), 'b')\n",
      "        self.input = input\n",
      "        self.p_y_given_x = T.nnet.softmax(T.dot(self.input, self.W) + self.b)\n",
      "        self.y_pred = T.argmax(self.p_y_given_x, axis=1)\n",
      "        self.output = self.y_pred\n",
      "        self.params = [self.W, self.b]\n",
      "\n",
      "    def negative_log_likelihood(self, y):\n",
      "        return -T.mean(T.log(self.p_y_given_x)[T.arange(y.shape[0]), y])\n",
      "\n",
      "    def negative_log_likelihood_sum(self, y):\n",
      "        return -T.sum(T.log(self.p_y_given_x)[T.arange(y.shape[0]), y])\n",
      "\n",
      "    def training_cost(self, y):\n",
      "        \"\"\" Wrapper for standard name \"\"\"\n",
      "        return self.negative_log_likelihood(y)\n",
      "\n",
      "    def errors(self, y):\n",
      "        if y.ndim != self.y_pred.ndim:\n",
      "            raise TypeError(\"!!! 'y' should have the same shape as 'self.y_pred'\",\n",
      "                (\"y\", y.type, \"y_pred\", self.y_pred.type))\n",
      "        if y.dtype.startswith('int'):\n",
      "            return T.mean(T.neq(self.y_pred, y))\n",
      "        else:\n",
      "            print(\"!!! y should be of int type\")\n",
      "            return T.mean(T.neq(self.y_pred, numpy.asarray(y, dtype='int')))\n",
      "        \n",
      "        \n",
      "#class PerceptronLoss: # TODO"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class NeuralNet(object):\n",
      "    \"\"\" Neural network (not regularized, without dropout) \"\"\"\n",
      "    def __init__(self, numpy_rng, theano_rng=None, \n",
      "                 n_ins=40*3,\n",
      "                 layers_types=[ReLU, ReLU, ReLU, ReLU, LogisticRegression],\n",
      "                 layers_sizes=[1024, 1024, 1024, 1024],\n",
      "                 n_outs=62*3,\n",
      "                 rho=0.95, eps=1.E-6,\n",
      "                 momentum=0.9, step_adapt_alpha=1.E-4,\n",
      "                 b1=0.1, b2=0.001,\n",
      "                 debugprint=False):\n",
      "        \"\"\"\n",
      "        Basic Neural Net class\n",
      "        \"\"\"\n",
      "        self.layers = []\n",
      "        self.params = []\n",
      "        self.n_layers = len(layers_types)\n",
      "        self.layers_types = layers_types\n",
      "        assert self.n_layers > 0\n",
      "        self._rho = rho  # ``momentum'' for adadelta (and discount/decay for RMSprop), alpha for Adam\n",
      "        self._eps = eps  # epsilon for adadelta (and for RMSprop and Adam)\n",
      "        self._momentum = momentum  # for RMSProp\n",
      "        self._b1 = b1\n",
      "        self._b2 = b2\n",
      "        self._accugrads = []  # for adadelta\n",
      "        self._accudeltas = []  # for adadelta\n",
      "        self._avggrads = []  # for RMSprop in the Alex Graves' variant\n",
      "        self._stepadapts = []  # for RMSprop with step adaptations\n",
      "        self._stepadapt_alpha = step_adapt_alpha\n",
      "\n",
      "        if theano_rng == None:\n",
      "            theano_rng = RandomStreams(numpy_rng.randint(2 ** 30))\n",
      "\n",
      "        self.x = T.fmatrix('x')\n",
      "        self.y = T.ivector('y')\n",
      "        \n",
      "        self.layers_ins = [n_ins] + layers_sizes\n",
      "        self.layers_outs = layers_sizes + [n_outs]\n",
      "        \n",
      "        layer_input = self.x\n",
      "        \n",
      "        for layer_type, n_in, n_out in zip(layers_types,\n",
      "                self.layers_ins, self.layers_outs):\n",
      "            this_layer = layer_type(rng=numpy_rng,\n",
      "                    input=layer_input, n_in=n_in, n_out=n_out)\n",
      "            assert hasattr(this_layer, 'output')\n",
      "            self.params.extend(this_layer.params)\n",
      "            self._accugrads.extend([build_shared_zeros(t.shape.eval(),\n",
      "                'accugrad') for t in this_layer.params])\n",
      "            self._accudeltas.extend([build_shared_zeros(t.shape.eval(),\n",
      "                'accudelta') for t in this_layer.params])\n",
      "            self._avggrads.extend([build_shared_zeros(t.shape.eval(),\n",
      "                'avggrad') for t in this_layer.params])\n",
      "            self._stepadapts.extend([shared(value=numpy.ones(t.shape.eval(),\n",
      "                dtype=theano.config.floatX),\n",
      "                name='stepadapt', borrow=True) for t in this_layer.params])\n",
      "            self.layers.append(this_layer)\n",
      "            layer_input = this_layer.output\n",
      "\n",
      "        assert hasattr(self.layers[-1], 'training_cost')\n",
      "        assert hasattr(self.layers[-1], 'errors')\n",
      "        self.mean_cost = self.layers[-1].negative_log_likelihood(self.y)\n",
      "        self.cost = self.layers[-1].training_cost(self.y)\n",
      "        if debugprint:\n",
      "            theano.printing.debugprint(self.cost)\n",
      "\n",
      "        self.errors = self.layers[-1].errors(self.y)\n",
      "\n",
      "    def __repr__(self):\n",
      "        dimensions_layers_str = map(lambda x: \"x\".join(map(str, x)),\n",
      "                                    zip(self.layers_ins, self.layers_outs))\n",
      "        return \"_\".join(map(lambda x: \"_\".join((x[0].__name__, x[1])),\n",
      "                            zip(self.layers_types, dimensions_layers_str)))\n",
      "\n",
      "\n",
      "    def get_SGD_trainer(self):\n",
      "        \"\"\" Returns a plain SGD minibatch trainer with learning rate as param. \"\"\"\n",
      "        batch_x = T.fmatrix('batch_x')\n",
      "        batch_y = T.ivector('batch_y')\n",
      "        learning_rate = T.fscalar('lr')  # learning rate\n",
      "        gparams = T.grad(self.mean_cost, self.params)  # all the gradients\n",
      "        updates = OrderedDict()\n",
      "        for param, gparam in zip(self.params, gparams):\n",
      "            updates[param] = param - gparam * learning_rate\n",
      "\n",
      "        train_fn = theano.function(inputs=[theano.Param(batch_x),\n",
      "                                           theano.Param(batch_y),\n",
      "                                           theano.Param(learning_rate)],\n",
      "                                   outputs=self.mean_cost,\n",
      "                                   updates=updates,\n",
      "                                   givens={self.x: batch_x, self.y: batch_y})\n",
      "\n",
      "        return train_fn\n",
      "\n",
      "    def get_adagrad_trainer(self):\n",
      "        \"\"\" Returns an Adagrad (Duchi et al. 2010) trainer using a learning rate.\n",
      "        \"\"\"\n",
      "        batch_x = T.fmatrix('batch_x')\n",
      "        batch_y = T.ivector('batch_y')\n",
      "        learning_rate = T.fscalar('lr')  # learning rate\n",
      "        gparams = T.grad(self.mean_cost, self.params)  # all the gradients\n",
      "        updates = OrderedDict()\n",
      "        for accugrad, param, gparam in zip(self._accugrads, self.params, gparams):\n",
      "            # c.f. Algorithm 1 in the Adadelta paper (Zeiler 2012)\n",
      "            agrad = accugrad + gparam * gparam\n",
      "            dx = - (learning_rate / T.sqrt(agrad + self._eps)) * gparam\n",
      "            updates[param] = param + dx\n",
      "            updates[accugrad] = agrad\n",
      "\n",
      "        train_fn = theano.function(inputs=[theano.Param(batch_x), \n",
      "            theano.Param(batch_y),\n",
      "            theano.Param(learning_rate)],\n",
      "            outputs=self.mean_cost,\n",
      "            updates=updates,\n",
      "            givens={self.x: batch_x, self.y: batch_y})\n",
      "\n",
      "        return train_fn\n",
      "\n",
      "    def get_adadelta_trainer(self):\n",
      "        \"\"\" Returns an Adadelta (Zeiler 2012) trainer using self._rho and\n",
      "        self._eps params. \"\"\"\n",
      "        batch_x = T.fmatrix('batch_x')\n",
      "        batch_y = T.ivector('batch_y')\n",
      "        gparams = T.grad(self.mean_cost, self.params)\n",
      "        updates = OrderedDict()\n",
      "        for accugrad, accudelta, param, gparam in zip(self._accugrads,\n",
      "                self._accudeltas, self.params, gparams):\n",
      "            # c.f. Algorithm 1 in the Adadelta paper (Zeiler 2012)\n",
      "            agrad = self._rho * accugrad + (1 - self._rho) * gparam * gparam\n",
      "            dx = - T.sqrt((accudelta + self._eps)\n",
      "                          / (agrad + self._eps)) * gparam\n",
      "            updates[accudelta] = (self._rho * accudelta\n",
      "                                  + (1 - self._rho) * dx * dx)\n",
      "            updates[param] = param + dx\n",
      "            updates[accugrad] = agrad\n",
      "\n",
      "        train_fn = theano.function(inputs=[theano.Param(batch_x),\n",
      "                                           theano.Param(batch_y)],\n",
      "                                   outputs=self.mean_cost,\n",
      "                                   updates=updates,\n",
      "                                   givens={self.x: batch_x, self.y: batch_y})\n",
      "\n",
      "        return train_fn\n",
      "\n",
      "    def get_rmsprop_trainer(self, with_step_adapt=True, nesterov=False):  # TODO Nesterov momentum\n",
      "        \"\"\" Returns an RmsProp (possibly Nesterov) (Sutskever 2013) trainer\n",
      "        using self._rho, self._eps and self._momentum params. \"\"\"\n",
      "        batch_x = T.fmatrix('batch_x')\n",
      "        batch_y = T.ivector('batch_y')\n",
      "        learning_rate = T.fscalar('lr')  # learning rate\n",
      "        gparams = T.grad(self.mean_cost, self.params)\n",
      "        updates = OrderedDict()\n",
      "        for accugrad, avggrad, accudelta, sa, param, gparam in zip(\n",
      "                self._accugrads, self._avggrads, self._accudeltas,\n",
      "                self._stepadapts, self.params, gparams):\n",
      "            acc_grad = self._rho * accugrad + (1 - self._rho) * gparam * gparam\n",
      "            avg_grad = self._rho * avggrad + (1 - self._rho) * gparam  # this decay/discount (self._rho) should differ from the one of the line above\n",
      "            ###scaled_grad = gparam / T.sqrt(acc_grad + self._eps)  # original RMSprop gradient scaling\n",
      "            scaled_grad = gparam / T.sqrt(acc_grad - avg_grad**2 + self._eps)  # Alex Graves' RMSprop variant (divide by a \"running stddev\" of the updates)\n",
      "            if with_step_adapt:\n",
      "                incr = sa * (1. + self._stepadapt_alpha)\n",
      "                #decr = sa * (1. - self._stepadapt_alpha)\n",
      "                decr = sa * (1. - 2*self._stepadapt_alpha)\n",
      "                ###steps = sa * T.switch(accudelta * -gparam >= 0, incr, decr)\n",
      "                steps = T.clip(T.switch(accudelta * -gparam >= 0, incr, decr), self._eps, 1./self._eps)  # bad overloading of self._eps!\n",
      "                scaled_grad = steps * scaled_grad\n",
      "                updates[sa] = steps\n",
      "            dx = self._momentum * accudelta - learning_rate * scaled_grad\n",
      "            updates[param] = param + dx\n",
      "            updates[accugrad] = acc_grad\n",
      "            updates[avggrad] = avg_grad\n",
      "            updates[accudelta] = dx\n",
      "\n",
      "        train_fn = theano.function(inputs=[theano.Param(batch_x),\n",
      "                                           theano.Param(batch_y),\n",
      "                                           theano.Param(learning_rate)],\n",
      "                                   outputs=self.mean_cost,\n",
      "                                   updates=updates,\n",
      "                                   givens={self.x: batch_x, self.y: batch_y})\n",
      "\n",
      "        return train_fn\n",
      "    \n",
      "    def get_adam_trainer(self):\n",
      "        \"\"\" Returns an Adam trainer as described in \n",
      "        ADAM: A METHOD FOR STOCHASTIC OPTIMIZATION, Kingma and Ba 2015 \"\"\"\n",
      "        batch_x = T.fmatrix('batch_x')\n",
      "        batch_y = T.ivector('batch_y')\n",
      "        self._i_t = shared(numpy.float32(0.))\n",
      "        self.lr = 0.0002\n",
      "        i_t = self._i_t + 1.\n",
      "        fix1 = 1. - (1. - self._b1)**i_t\n",
      "        fix2 = 1. - (1. - self._b2)**i_t\n",
      "        lr_t = self.lr * (T.sqrt(fix2) / fix1)\n",
      "        gparams = T.grad(self.mean_cost, self.params)\n",
      "        updates = OrderedDict()\n",
      "        for accugrad, accudelta, param, gparam in zip(self._accugrads, self._accudeltas, self.params, gparams):\n",
      "            m_t = (self._b1 * gparam) + ((1. - self._b1) * accugrad)\n",
      "            v_t = (self._b2 * T.sqr(gparam)) + ((1. - self._b2) * accudelta)\n",
      "            #m_t_h = m_t / (1 - (1-self._b1)**i_t)\n",
      "            #v_t_h = v_t / (1 - (1-self._b2)**i_t)\n",
      "            #g_t = m_t_h / (T.sqrt(v_t_h) + self._eps)\n",
      "            g_t = m_t / (T.sqrt(v_t) + self._eps)\n",
      "            updates[param] = param - (lr_t * g_t)\n",
      "            updates[accugrad] = m_t\n",
      "            updates[accudelta] = v_t\n",
      "        updates[self._i_t] = i_t\n",
      "        \n",
      "        train_fn = theano.function(inputs=[theano.Param(batch_x),\n",
      "                                           theano.Param(batch_y)],\n",
      "                                   outputs=self.mean_cost,\n",
      "                                   updates=updates,\n",
      "                                   givens={self.x: batch_x, self.y: batch_y})\n",
      "\n",
      "        return train_fn\n",
      "        \n",
      "\n",
      "    def score_classif(self, given_set):\n",
      "        \"\"\" Returns functions to get current classification errors. \"\"\"\n",
      "        batch_x = T.fmatrix('batch_x')\n",
      "        batch_y = T.ivector('batch_y')\n",
      "        score = theano.function(inputs=[theano.Param(batch_x),\n",
      "                                        theano.Param(batch_y)],\n",
      "                                outputs=self.errors,\n",
      "                                givens={self.x: batch_x, self.y: batch_y})\n",
      "\n",
      "        def scoref():\n",
      "            \"\"\" returned function that scans the entire set given as input \"\"\"\n",
      "            return [score(batch_x, batch_y) for batch_x, batch_y in given_set]\n",
      "\n",
      "        return scoref\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class RegularizedNet(NeuralNet):\n",
      "    \"\"\" Neural net with L1 and L2 regularization \"\"\"\n",
      "    def __init__(self, numpy_rng, theano_rng=None,\n",
      "                 n_ins=100,\n",
      "                 layers_types=[ReLU, ReLU, ReLU, LogisticRegression],\n",
      "                 layers_sizes=[1024, 1024, 1024],\n",
      "                 n_outs=2,\n",
      "                 rho=0.95, eps=1.E-8,\n",
      "                 L1_reg=0.1,\n",
      "                 L2_reg=0.1,\n",
      "                 debugprint=False):\n",
      "        \"\"\"\n",
      "        A deep neural net with possible L1 and/or L2 regularization.\n",
      "        \"\"\"\n",
      "        super(RegularizedNet, self).__init__(numpy_rng, theano_rng, n_ins,\n",
      "                layers_types, layers_sizes, n_outs, rho, eps, debugprint)\n",
      "\n",
      "        self.L1_reg = L1_reg\n",
      "        self.L2_reg = L2_reg\n",
      "        L1 = shared(0.)\n",
      "        for param in self.params:\n",
      "            L1 += T.sum(abs(param))\n",
      "        if L1_reg > 0.:\n",
      "            self.cost = self.cost + L1_reg * L1\n",
      "        L2 = shared(0.)\n",
      "        for param in self.params:\n",
      "            L2 += T.sum(param ** 2)\n",
      "        if L2_reg > 0.:\n",
      "            self.cost = self.cost + L2_reg * L2\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class DropoutNet(NeuralNet):\n",
      "    \"\"\" Neural net with dropout (see Hinton's et al. paper) \"\"\"\n",
      "    def __init__(self, numpy_rng, theano_rng=None,\n",
      "                 n_ins=40*3,\n",
      "                 layers_types=[ReLU, ReLU, ReLU, ReLU, LogisticRegression],\n",
      "                 layers_sizes=[4000, 4000, 4000, 4000],\n",
      "                 dropout_rates=[0.2, 0.5, 0.5, 0.5, 0.5],\n",
      "                 n_outs=62 * 3,\n",
      "                 rho=0.98, eps=1.E-6,\n",
      "                 debugprint=False):\n",
      "        \"\"\"\n",
      "        A dropout-regularized neural net.\n",
      "        \"\"\"\n",
      "        super(DropoutNet, self).__init__(numpy_rng, theano_rng, n_ins,\n",
      "                layers_types, layers_sizes, n_outs, rho, eps, debugprint)\n",
      "\n",
      "        self.dropout_rates = dropout_rates\n",
      "        dropout_layer_input = dropout(numpy_rng, self.x, p=dropout_rates[0])\n",
      "        self.dropout_layers = []\n",
      "\n",
      "        for layer, layer_type, n_in, n_out, dr in zip(self.layers,\n",
      "                layers_types, self.layers_ins, self.layers_outs,\n",
      "                dropout_rates[1:] + [0]):  # !!! we do not dropout anything\n",
      "                                           # from the last layer !!!\n",
      "            if dr:\n",
      "                this_layer = layer_type(rng=numpy_rng,\n",
      "                        input=dropout_layer_input, n_in=n_in, n_out=n_out,\n",
      "                        W=layer.W * 1. / (1. - dr),\n",
      "                        b=layer.b * 1. / (1. - dr))\n",
      "                # N.B. dropout with dr==1 does not dropanything!!\n",
      "                this_layer.output = dropout(numpy_rng, this_layer.output, dr)\n",
      "            else:\n",
      "                this_layer = layer_type(rng=numpy_rng,\n",
      "                        input=dropout_layer_input, n_in=n_in, n_out=n_out,\n",
      "                        W=layer.W, b=layer.b)\n",
      "\n",
      "            assert hasattr(this_layer, 'output')\n",
      "            self.dropout_layers.append(this_layer)\n",
      "            dropout_layer_input = this_layer.output\n",
      "\n",
      "        assert hasattr(self.layers[-1], 'training_cost')\n",
      "        assert hasattr(self.layers[-1], 'errors')\n",
      "        # TODO standardize cost\n",
      "        # these are the dropout costs\n",
      "        self.mean_cost = self.dropout_layers[-1].negative_log_likelihood(self.y)\n",
      "        self.cost = self.dropout_layers[-1].training_cost(self.y)\n",
      "\n",
      "        # these is the non-dropout errors\n",
      "        self.errors = self.layers[-1].errors(self.y)\n",
      "\n",
      "    def __repr__(self):\n",
      "        return super(DropoutNet, self).__repr__() + \"\\n\"\\\n",
      "                + \"dropout rates: \" + str(self.dropout_rates)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def add_fit_and_score(class_to_chg):\n",
      "    \"\"\" Mutates a class to add the fit() and score() functions to a NeuralNet.\n",
      "    \"\"\"\n",
      "    from types import MethodType\n",
      "    def fit(self, x_train, y_train, x_dev=None, y_dev=None,\n",
      "            max_epochs=20, early_stopping=True, split_ratio=0.1, # TODO 100+ epochs\n",
      "            method='adadelta', verbose=False, plot=False):\n",
      "        \"\"\"\n",
      "        TODO\n",
      "        \"\"\"\n",
      "        import time, copy\n",
      "        if x_dev == None or y_dev == None:\n",
      "            from sklearn.cross_validation import train_test_split\n",
      "            x_train, x_dev, y_train, y_dev = train_test_split(x_train, y_train,\n",
      "                    test_size=split_ratio, random_state=42)\n",
      "        if method == 'sgd':\n",
      "            train_fn = self.get_SGD_trainer()\n",
      "        elif method == 'adagrad':\n",
      "            train_fn = self.get_adagrad_trainer()\n",
      "        elif method == 'adadelta':\n",
      "            train_fn = self.get_adadelta_trainer()\n",
      "        elif method == 'adam':\n",
      "            train_fn = self.get_adam_trainer()\n",
      "        elif method == 'rmsprop':\n",
      "            train_fn = self.get_rmsprop_trainer(with_step_adapt=True,\n",
      "                    nesterov=False)\n",
      "        train_set_iterator = DatasetMiniBatchIterator(x_train, y_train)\n",
      "        dev_set_iterator = DatasetMiniBatchIterator(x_dev, y_dev)\n",
      "        train_scoref = self.score_classif(train_set_iterator)\n",
      "        dev_scoref = self.score_classif(dev_set_iterator)\n",
      "        best_dev_loss = numpy.inf\n",
      "        epoch = 0\n",
      "        # TODO early stopping (not just cross val, also stop training)\n",
      "        if plot:\n",
      "            verbose = True\n",
      "            self._costs = []\n",
      "            self._train_errors = []\n",
      "            self._dev_errors = []\n",
      "            self._updates = []\n",
      "\n",
      "        init_lr = INIT_LR\n",
      "        if method == 'rmsprop':\n",
      "            init_lr = 1.E-6  # TODO REMOVE HACK\n",
      "        n_seen = 0\n",
      "        while epoch < max_epochs:\n",
      "            #first TODO: update learning rates when not using adadelta!\n",
      "            #lr = init_lr / (1 + init_lr * L2_LAMBDA * math.log(1+n_seen))\n",
      "            #lr = init_lr / math.sqrt(1 + init_lr * L2_LAMBDA * n_seen/BATCH_SIZE) # try these\n",
      "            lr = init_lr\n",
      "            if not verbose:\n",
      "                sys.stdout.write(\"\\r%0.2f%%\" % (epoch * 100./ max_epochs))\n",
      "                sys.stdout.flush()\n",
      "            avg_costs = []\n",
      "            timer = time.time()\n",
      "            for x, y in train_set_iterator:\n",
      "                if method == 'sgd' or method == 'adagrad' or method == 'rmsprop':\n",
      "                    #avg_cost = train_fn(x, y, lr=1.E-2)\n",
      "                    avg_cost = train_fn(x, y, lr=lr)\n",
      "                elif method == 'adadelta' or method == 'adam':\n",
      "                    avg_cost = train_fn(x, y)\n",
      "                if type(avg_cost) == list:\n",
      "                    avg_costs.append(avg_cost[0])\n",
      "                else:\n",
      "                    avg_costs.append(avg_cost)\n",
      "            if verbose:\n",
      "                mean_costs = numpy.mean(avg_costs)\n",
      "                mean_train_errors = numpy.mean(train_scoref())\n",
      "                print('  epoch %i took %f seconds' %\n",
      "                      (epoch, time.time() - timer))\n",
      "                print('  epoch %i, avg costs %f' %\n",
      "                      (epoch, mean_costs))\n",
      "                print('  epoch %i, training error %f' %\n",
      "                      (epoch, mean_train_errors))\n",
      "                if plot:\n",
      "                    self._costs.append(mean_costs)\n",
      "                    self._train_errors.append(mean_train_errors)\n",
      "            dev_errors = numpy.mean(dev_scoref())\n",
      "            if plot:\n",
      "                self._dev_errors.append(dev_errors)\n",
      "            if dev_errors < best_dev_loss:\n",
      "                best_dev_loss = dev_errors\n",
      "                best_params = copy.deepcopy(self.params)\n",
      "                if verbose:\n",
      "                    print('!!!  epoch %i, validation error of best model %f' %\n",
      "                          (epoch, dev_errors))\n",
      "            epoch += 1\n",
      "            n_seen += x_train.shape[0]\n",
      "        if not verbose:\n",
      "            print(\"\")\n",
      "        for i, param in enumerate(best_params):\n",
      "            self.params[i] = param\n",
      "\n",
      "    def score(self, x, y):\n",
      "        \"\"\" error rates \"\"\"\n",
      "        iterator = DatasetMiniBatchIterator(x, y)\n",
      "        scoref = self.score_classif(iterator)\n",
      "        return numpy.mean(scoref())\n",
      "\n",
      "    class_to_chg.fit = MethodType(fit, None, class_to_chg)\n",
      "    class_to_chg.score = MethodType(score, None, class_to_chg)\n",
      "\n",
      "\n",
      "def train_models(x_train, y_train, x_test, y_test, n_features, n_outs,\n",
      "        x_dev=None, y_dev=None,\n",
      "        use_dropout=False, n_epochs=100, numpy_rng=None,\n",
      "        svms=False, nb=False, deepnn=True,\n",
      "        verbose=False, plot=False, name=''):\n",
      "    if svms:\n",
      "        print(\"Linear SVM\")\n",
      "        classifier = svm.SVC(gamma=0.001)\n",
      "        print(classifier)\n",
      "        classifier.fit(x_train, y_train)\n",
      "        print(\"score: %f\" % classifier.score(x_test, y_test))\n",
      "\n",
      "        print(\"RBF-kernel SVM\")\n",
      "        classifier = svm.SVC(kernel='rbf', class_weight='auto')\n",
      "        print(classifier)\n",
      "        classifier.fit(x_train, y_train)\n",
      "        print(\"score: %f\" % classifier.score(x_test, y_test))\n",
      "\n",
      "    if nb:\n",
      "        print(\"Multinomial Naive Bayes\")\n",
      "        classifier = naive_bayes.MultinomialNB()\n",
      "        print(classifier)\n",
      "        classifier.fit(x_train, y_train)\n",
      "        print(\"score: %f\" % classifier.score(x_test, y_test))\n",
      "\n",
      "    if deepnn:\n",
      "        import warnings\n",
      "        warnings.filterwarnings(\"ignore\")  # TODO remove\n",
      "\n",
      "        if use_dropout:\n",
      "            n_epochs *= 4\n",
      "            pass\n",
      "\n",
      "        def new_dnn(dropout=False):\n",
      "            if dropout:\n",
      "                print(\"Dropout DNN\")\n",
      "                return DropoutNet(numpy_rng=numpy_rng, n_ins=n_features,\n",
      "                    layers_types=[ReLU, ReLU, ReLU, ReLU, LogisticRegression],\n",
      "                    layers_sizes=[2000, 2000, 2000, 2000],\n",
      "                    dropout_rates=[0.2, 0.5, 0.5, 0.5, 0.5],\n",
      "                    n_outs=n_outs,\n",
      "                    debugprint=0)\n",
      "            else:\n",
      "                print(\"Simple (regularized) DNN\")\n",
      "                return RegularizedNet(numpy_rng=numpy_rng, n_ins=n_features,\n",
      "                    layers_types=[LogisticRegression],\n",
      "                    layers_sizes=[],\n",
      "                    #layers_types=[ReLU, ReLU, ReLU, LogisticRegression],\n",
      "                    #layers_sizes=[1000, 1000, 1000],\n",
      "                    #layers_types=[ReLU, LogisticRegression],\n",
      "                    #layers_sizes=[200],\n",
      "                    n_outs=n_outs,\n",
      "                    L1_reg=0.,\n",
      "                    L2_reg=L2_LAMBDA,\n",
      "                    debugprint=1)\n",
      "\n",
      "        import matplotlib.pyplot as plt\n",
      "        fig = plt.gcf() #plt.figure()\n",
      "        fig.set_size_inches(16,10)\n",
      "        ax1 = plt.subplot(221)\n",
      "        ax2 = plt.subplot(222)\n",
      "        ax3 = plt.subplot(223)\n",
      "        ax4 = plt.subplot(224)  # TODO updates of the weights\n",
      "        #methods = ['sgd', 'adagrad', 'adadelta']\n",
      "        methods = ['adam', 'adadelta']\n",
      "        #methods = ['rmsprop', 'adadelta', 'adagrad']\n",
      "        for method in methods:\n",
      "            dnn = new_dnn(use_dropout)\n",
      "            print dnn\n",
      "            dnn.fit(x_train, y_train, x_dev, y_dev, max_epochs=n_epochs,\n",
      "                    method=method, verbose=verbose, plot=plot)\n",
      "            test_error = dnn.score(x_test, y_test)\n",
      "            print(\"score: %f\" % (1. - test_error))\n",
      "            ax1.plot(numpy.log10(dnn._costs), label=method)\n",
      "            #ax2.plot(numpy.log10(dnn._train_errors), label=method)\n",
      "            #ax3.plot(numpy.log10(dnn._dev_errors), label=method)\n",
      "            ax2.plot(dnn._train_errors, label=method)\n",
      "            ax3.plot(dnn._dev_errors, label=method)\n",
      "            #ax4.plot(dnn._updates, label=method) TODO\n",
      "            ax4.plot([test_error for _ in range(10)], label=method)\n",
      "        ax1.set_xlabel('epoch')\n",
      "        ax1.set_ylabel('cost (log10)')\n",
      "        ax2.set_xlabel('epoch')\n",
      "        ax2.set_ylabel('train error')\n",
      "        ax3.set_xlabel('epoch')\n",
      "        ax3.set_ylabel('dev error')\n",
      "        ax4.set_ylabel('test error')\n",
      "        plt.legend()\n",
      "        plt.tight_layout()\n",
      "        plt.show()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#main function\n",
      "\n",
      "def run():\n",
      "    add_fit_and_score(DropoutNet)\n",
      "    add_fit_and_score(RegularizedNet)\n",
      "    from sklearn import datasets, svm, naive_bayes\n",
      "    from sklearn import cross_validation, preprocessing\n",
      "    \n",
      "\n",
      "    if MNIST:\n",
      "        from sklearn.datasets import fetch_mldata\n",
      "        mnist = fetch_mldata('MNIST original')\n",
      "        X = numpy.asarray(mnist.data, dtype='float32')\n",
      "        #X = preprocessing.scale(X)\n",
      "        X /= 255.\n",
      "        y = numpy.asarray(mnist.target, dtype='int32')\n",
      "        print(\"Total dataset size:\")\n",
      "        print(\"n samples: %d\" % X.shape[0])\n",
      "        print(\"n features: %d\" % X.shape[1])\n",
      "        print(\"n classes: %d\" % len(set(y)))\n",
      "        x_train, x_test = X[:-10000], X[-10000:]\n",
      "        y_train, y_test = y[:-10000], y[-10000:]\n",
      "\n",
      "        train_models(x_train, y_train, x_test, y_test, X.shape[1],\n",
      "                     len(set(y)), numpy_rng=numpy.random.RandomState(123),\n",
      "                     use_dropout=False, n_epochs=30,\n",
      "                     verbose=True, plot=True, name='mnist_L2')\n",
      "        #train_models(x_train, y_train, x_test, y_test, X.shape[1],\n",
      "        #             len(set(y)), numpy_rng=numpy.random.RandomState(123),\n",
      "        #             use_dropout=True,\n",
      "        #             verbose=True, plot=True, name='mnist_dropout')\n",
      "\n",
      "    if DIGITS:\n",
      "        digits = datasets.load_digits()\n",
      "        data = numpy.asarray(digits.data, dtype='float32')\n",
      "        target = numpy.asarray(digits.target, dtype='int32')\n",
      "        x = preprocessing.scale(data)\n",
      "        x_train, x_test, y_train, y_test = cross_validation.train_test_split(\n",
      "                x, target, test_size=0.2, random_state=42)\n",
      "        train_models(x_train, y_train, x_test, y_test, x.shape[1],\n",
      "                     len(set(target)), numpy_rng=numpy.random.RandomState(123),\n",
      "                     verbose=True, plot=True, name='digits')\n",
      "\n",
      "    if FACES:\n",
      "        import logging\n",
      "        logging.basicConfig(level=logging.INFO,\n",
      "                            format='%(asctime)s %(message)s')\n",
      "        lfw_people = datasets.fetch_lfw_people(min_faces_per_person=70,\n",
      "                                               resize=0.4)\n",
      "        X = numpy.asarray(lfw_people.data, dtype='float32')\n",
      "        X = preprocessing.scale(X)\n",
      "        y = numpy.asarray(lfw_people.target, dtype='int32')\n",
      "        target_names = lfw_people.target_names\n",
      "        print(\"Total dataset size:\")\n",
      "        print(\"n samples: %d\" % X.shape[0])\n",
      "        print(\"n features: %d\" % X.shape[1])\n",
      "        print(\"n classes: %d\" % target_names.shape[0])\n",
      "        x_train, x_test, y_train, y_test = cross_validation.train_test_split(\n",
      "                    X, y, test_size=0.2, random_state=42)\n",
      "\n",
      "        train_models(x_train, y_train, x_test, y_test, X.shape[1],\n",
      "                     len(set(y)), numpy_rng=numpy.random.RandomState(123),\n",
      "                     verbose=True, plot=True, name='faces')\n",
      "\n",
      "    if TWENTYNEWSGROUPS:\n",
      "        from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "        newsgroups_train = datasets.fetch_20newsgroups(subset='train')\n",
      "        vectorizer = TfidfVectorizer(encoding='latin-1', max_features=10000)\n",
      "        #vectorizer = HashingVectorizer(encoding='latin-1')\n",
      "        x_train = vectorizer.fit_transform(newsgroups_train.data)\n",
      "        x_train = numpy.asarray(x_train.todense(), dtype='float32')\n",
      "        y_train = numpy.asarray(newsgroups_train.target, dtype='int32')\n",
      "        newsgroups_test = datasets.fetch_20newsgroups(subset='test')\n",
      "        x_test = vectorizer.transform(newsgroups_test.data)\n",
      "        x_test = numpy.asarray(x_test.todense(), dtype='float32')\n",
      "        y_test = numpy.asarray(newsgroups_test.target, dtype='int32')\n",
      "        train_models(x_train, y_train, x_test, y_test, x_train.shape[1],\n",
      "                     len(set(y_train)),\n",
      "                     numpy_rng=numpy.random.RandomState(123),\n",
      "                     svms=False, nb=True, deepnn=True,\n",
      "                     verbose=True, plot=True, name='20newsgroups')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "run()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Total dataset size:\n",
        "n samples: 70000\n",
        "n features: 784\n",
        "n classes: 10\n",
        "Simple (regularized) DNN"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LogisticRegression_784x10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 0 took 0.269893 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 0, avg costs 1.243363\n",
        "  epoch 0, training error 0.155833\n",
        "!!!  epoch 0, validation error of best model 0.153500\n",
        "  epoch 1 took 0.297565 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 1, avg costs 0.633141\n",
        "  epoch 1, training error 0.126481\n",
        "!!!  epoch 1, validation error of best model 0.126500\n",
        "  epoch 2 took 0.285746 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 2, avg costs 0.492538\n",
        "  epoch 2, training error 0.112778\n",
        "!!!  epoch 2, validation error of best model 0.115833\n",
        "  epoch 3 took 0.299956 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 3, avg costs 0.428124\n",
        "  epoch 3, training error 0.104481\n",
        "!!!  epoch 3, validation error of best model 0.109833\n",
        "  epoch 4 took 0.291172 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 4, avg costs 0.390489\n",
        "  epoch 4, training error 0.099389\n",
        "!!!  epoch 4, validation error of best model 0.103000\n",
        "  epoch 5 took 0.316594 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 5, avg costs 0.365602\n",
        "  epoch 5, training error 0.095093\n",
        "!!!  epoch 5, validation error of best model 0.099667\n",
        "  epoch 6 took 0.281905 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 6, avg costs 0.347869\n",
        "  epoch 6, training error 0.091426\n",
        "!!!  epoch 6, validation error of best model 0.097167\n",
        "  epoch 7 took 0.281674 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 7, avg costs 0.334582\n",
        "  epoch 7, training error 0.089111\n",
        "!!!  epoch 7, validation error of best model 0.094500\n",
        "  epoch 8 took 0.288380 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 8, avg costs 0.324257\n",
        "  epoch 8, training error 0.086981\n",
        "!!!  epoch 8, validation error of best model 0.093000\n",
        "  epoch 9 took 0.286906 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 9, avg costs 0.316005\n",
        "  epoch 9, training error 0.085222\n",
        "!!!  epoch 9, validation error of best model 0.092000\n",
        "  epoch 10 took 0.292030 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 10, avg costs 0.309255\n",
        "  epoch 10, training error 0.083815\n",
        "!!!  epoch 10, validation error of best model 0.090500\n",
        "  epoch 11 took 0.279655 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 11, avg costs 0.303626\n",
        "  epoch 11, training error 0.082685\n",
        "!!!  epoch 11, validation error of best model 0.089000\n",
        "  epoch 12 took 0.294217 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 12, avg costs 0.298852\n",
        "  epoch 12, training error 0.081741\n",
        "!!!  epoch 12, validation error of best model 0.088667\n",
        "  epoch 13 took 0.304461 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 13, avg costs 0.294745\n",
        "  epoch 13, training error 0.080519\n",
        "!!!  epoch 13, validation error of best model 0.087167\n",
        "  epoch 14 took 0.279682 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 14, avg costs 0.291166\n",
        "  epoch 14, training error 0.079500\n",
        "!!!  epoch 14, validation error of best model 0.086667\n",
        "  epoch 15 took 0.277173 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 15, avg costs 0.288012\n",
        "  epoch 15, training error 0.078667\n",
        "!!!  epoch 15, validation error of best model 0.086167\n",
        "  epoch 16 took 0.293082 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 16, avg costs 0.285206\n",
        "  epoch 16, training error 0.078111\n",
        "!!!  epoch 16, validation error of best model 0.085667\n",
        "  epoch 17 took 0.302496 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 17, avg costs 0.282688\n",
        "  epoch 17, training error 0.077463\n",
        "!!!  epoch 17, validation error of best model 0.085167\n",
        "  epoch 18 took 0.283735 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 18, avg costs 0.280410\n",
        "  epoch 18, training error 0.076889\n",
        "!!!  epoch 18, validation error of best model 0.084667\n",
        "  epoch 19 took 0.287550 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 19, avg costs 0.278337\n",
        "  epoch 19, training error 0.076574\n",
        "!!!  epoch 19, validation error of best model 0.084500\n",
        "  epoch 20 took 0.281636 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 20, avg costs 0.276438\n",
        "  epoch 20, training error 0.076111\n",
        "!!!  epoch 20, validation error of best model 0.083833\n",
        "  epoch 21 took 0.289907 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 21, avg costs 0.274690\n",
        "  epoch 21, training error 0.075519\n",
        "  epoch 22 took 0.290426 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 22, avg costs 0.273072\n",
        "  epoch 22, training error 0.075111\n",
        "!!!  epoch 22, validation error of best model 0.083500\n",
        "  epoch 23 took 0.283991 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 23, avg costs 0.271569\n",
        "  epoch 23, training error 0.074741\n",
        "  epoch 24 took 0.276365 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 24, avg costs 0.270167\n",
        "  epoch 24, training error 0.074352\n",
        "  epoch 25 took 0.326764 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 25, avg costs 0.268854\n",
        "  epoch 25, training error 0.073870\n",
        "  epoch 26 took 0.307149 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 26, avg costs 0.267622\n",
        "  epoch 26, training error 0.073667\n",
        "!!!  epoch 26, validation error of best model 0.083167\n",
        "  epoch 27 took 0.313843 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 27, avg costs 0.266461\n",
        "  epoch 27, training error 0.073296\n",
        "!!!  epoch 27, validation error of best model 0.082833\n",
        "  epoch 28 took 0.289039 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 28, avg costs 0.265364\n",
        "  epoch 28, training error 0.073111\n",
        "  epoch 29 took 0.280149 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 29, avg costs 0.264326\n",
        "  epoch 29, training error 0.072611\n",
        "!!!  epoch 29, validation error of best model 0.082667\n",
        "score: 0.924200"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Simple (regularized) DNN\n",
        "LogisticRegression_784x10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 0 took 0.311120 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 0, avg costs 0.923582\n",
        "  epoch 0, training error 0.128704\n",
        "!!!  epoch 0, validation error of best model 0.130167\n",
        "  epoch 1 took 0.320057 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 1, avg costs 0.452976\n",
        "  epoch 1, training error 0.105963\n",
        "!!!  epoch 1, validation error of best model 0.109500\n",
        "  epoch 2 took 0.326817 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 2, avg costs 0.378660\n",
        "  epoch 2, training error 0.097426\n",
        "!!!  epoch 2, validation error of best model 0.102000\n",
        "  epoch 3 took 0.308853 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 3, avg costs 0.348301\n",
        "  epoch 3, training error 0.092667\n",
        "!!!  epoch 3, validation error of best model 0.097333\n",
        "  epoch 4 took 0.327724 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 4, avg costs 0.331119\n",
        "  epoch 4, training error 0.089056\n",
        "!!!  epoch 4, validation error of best model 0.094667\n",
        "  epoch 5 took 0.311835 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 5, avg costs 0.319697\n",
        "  epoch 5, training error 0.086667\n",
        "!!!  epoch 5, validation error of best model 0.092833\n",
        "  epoch 6 took 0.324327 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 6, avg costs 0.311373\n",
        "  epoch 6, training error 0.084944\n",
        "!!!  epoch 6, validation error of best model 0.091500\n",
        "  epoch 7 took 0.327300 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 7, avg costs 0.304943\n",
        "  epoch 7, training error 0.083370\n",
        "!!!  epoch 7, validation error of best model 0.089667\n",
        "  epoch 8 took 0.313637 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 8, avg costs 0.299771\n",
        "  epoch 8, training error 0.082148\n",
        "!!!  epoch 8, validation error of best model 0.088500\n",
        "  epoch 9 took 0.306343 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 9, avg costs 0.295485\n",
        "  epoch 9, training error 0.081315\n",
        "!!!  epoch 9, validation error of best model 0.087833\n",
        "  epoch 10 took 0.329969 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 10, avg costs 0.291853\n",
        "  epoch 10, training error 0.080315\n",
        "!!!  epoch 10, validation error of best model 0.087667\n",
        "  epoch 11 took 0.311047 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 11, avg costs 0.288719\n",
        "  epoch 11, training error 0.079463\n",
        "!!!  epoch 11, validation error of best model 0.087333\n",
        "  epoch 12 took 0.306574 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 12, avg costs 0.285976\n",
        "  epoch 12, training error 0.078556\n",
        "!!!  epoch 12, validation error of best model 0.087000\n",
        "  epoch 13 took 0.318012 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 13, avg costs 0.283545\n",
        "  epoch 13, training error 0.077926\n",
        "!!!  epoch 13, validation error of best model 0.086500\n",
        "  epoch 14 took 0.318956 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 14, avg costs 0.281369\n",
        "  epoch 14, training error 0.077148\n",
        "!!!  epoch 14, validation error of best model 0.085833\n",
        "  epoch 15 took 0.307148 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 15, avg costs 0.279405\n",
        "  epoch 15, training error 0.076315\n",
        "!!!  epoch 15, validation error of best model 0.085667\n",
        "  epoch 16 took 0.307458 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 16, avg costs 0.277618\n",
        "  epoch 16, training error 0.075815\n",
        "!!!  epoch 16, validation error of best model 0.085333\n",
        "  epoch 17 took 0.312092 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 17, avg costs 0.275983\n",
        "  epoch 17, training error 0.075426\n",
        "!!!  epoch 17, validation error of best model 0.085000\n",
        "  epoch 18 took 0.304722 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 18, avg costs 0.274479\n",
        "  epoch 18, training error 0.074926\n",
        "  epoch 19 took 0.311247 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 19, avg costs 0.273086\n",
        "  epoch 19, training error 0.074463\n",
        "  epoch 20 took 0.340049 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 20, avg costs 0.271793\n",
        "  epoch 20, training error 0.074241\n",
        "  epoch 21 took 0.307233 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 21, avg costs 0.270587\n",
        "  epoch 21, training error 0.073889\n",
        "!!!  epoch 21, validation error of best model 0.084833\n",
        "  epoch 22 took 0.347523 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 22, avg costs 0.269458\n",
        "  epoch 22, training error 0.073574\n",
        "  epoch 23 took 0.324835 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 23, avg costs 0.268398\n",
        "  epoch 23, training error 0.073204\n",
        "!!!  epoch 23, validation error of best model 0.083667\n",
        "  epoch 24 took 0.360615 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 24, avg costs 0.267400\n",
        "  epoch 24, training error 0.072704\n",
        "!!!  epoch 24, validation error of best model 0.083500\n",
        "  epoch 25 took 0.377638 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 25, avg costs 0.266457\n",
        "  epoch 25, training error 0.072611\n",
        "  epoch 26 took 0.306555 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 26, avg costs 0.265566\n",
        "  epoch 26, training error 0.072370\n",
        "!!!  epoch 26, validation error of best model 0.083167\n",
        "  epoch 27 took 0.309302 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 27, avg costs 0.264720\n",
        "  epoch 27, training error 0.072185\n",
        "  epoch 28 took 0.333637 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 28, avg costs 0.263916\n",
        "  epoch 28, training error 0.071907\n",
        "  epoch 29 took 0.324232 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  epoch 29, avg costs 0.263151\n",
        "  epoch 29, training error 0.071722\n",
        "score: 0.924300"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAABHkAAALLCAYAAABtvl6cAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmZnlgIM8ZmZmZmZmZmY58P/ao7byiq+GKwAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x1118faa10>"
       ]
      }
     ],
     "prompt_number": 22
    }
   ],
   "metadata": {}
  }
 ]
}